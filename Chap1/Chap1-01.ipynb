{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.01 特征归一化\n",
    "数据如有不同的量纲，则可能会影响到数据分析的结果。为了消除数据特征之间的量纲影响，我们需要对特征进行归一化处理，使得不同指标之间具有可比性。  例如，分析一个人的身高和体重对健康的影响，如果使用米（m）和千克（kg）作为单位，那么身高特征会在1.6～1.8m的数值范围内，体重特征会在50～100kg的范围内，分析出来的结果显然会倾向于数值差别比较大的体重特征。想要得到更为准确的结果，就需要进行特征归一化（Normalization）处理，使各指标处于同一数值量级，以便进行分析。\n",
    "\n",
    "## 特征归一化常用方法\n",
    "\n",
    "- **线性函数归一化**（Min-Max Scaling）：将原始数据进行线性变换，映射到[0, 1]的范围，实现对原始数据的等比缩放。\n",
    "  \n",
    "  归一化公式如下：$ X_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}} $\n",
    "  \n",
    "- **零均值归一化**（Z-Score Normalization）：它会将原始数据映射到均值为0、标准差为1的分布上。\n",
    "\n",
    "  假设原始特征的均值为μ、标准差为σ，那么归一化公式定义为:$ z = \\frac{x - \\mu }{ \\sigma } $\n",
    "\n",
    "## Q1:为什么需要对数值类型的特征做归一化？\n",
    "\n",
    "对数值类型的特征做归一化可以将所有的特征都统一到一个大致相同的数值区间内。\n",
    "\n",
    "下面借助随机梯度下降的实例来说明归一化的重要性：\n",
    "\n",
    "假设有两种数值型特征，$ x_{1} $的取值范围为 [0, 10]，$ x_{2} $的取值范围为[0, 3]，于是可以构造一个目标函数符合下方左边的等值图。\n",
    "\n",
    " ![数据归一化对梯度下降收敛速度产生的影响](img/1-1-q1.png)\n",
    " \n",
    " 在学习速率相同的情况下，$ x_{1} $的更新速度会大于$ x_{2} $，需要较多的迭代才能找到最优解。如果将$ x_{1} $和$ x_{2} $归一化到相同的数值区间后，优化目标的等值图会变为右图中的圆形，$ x_{1} $和$ x_{2} $的更新速度变得更为一致，容易更快地通过梯度下降找到最优解。\n",
    " \n",
    "## 特征归一化适用情况\n",
    "\n",
    "在实际应用中，**通过梯度下降法求解的模型通常是需要归一化的** ，包括线性回归、逻辑回归、支持向量机、神经网络等模型。\n",
    "\n",
    "但对于**决策树模型则并不适用** ，以C4.5为例，决策树在进行节点分裂时主要依据数据集D关于特征x的信息增益比（详见第3章第3节），而**信息增益比跟特征是否经过归一化是无关的，因为归一化并不会改变样本在特征x上的信息增益。** \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
